{"cells":[{"cell_type":"markdown","id":"0019f524","metadata":{"id":"0019f524"},"source":["# MeanShift Algorithm #\n","*taken from: https://github.com/opencv/opencv/blob/4dfbbabf8bdefcc9c7111f40e0ac2248d751daef/samples/python/tutorial_code/video/meanshift/meanshift.py"]},{"cell_type":"code","execution_count":null,"id":"2cc80bf9","metadata":{"id":"2cc80bf9"},"outputs":[],"source":["import numpy as np\n","import cv2 as cv\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('image', type=str, help='image path')\n","args = parser.parse_args(['.\\Res\\car.mp4']) #File path here\n","\n","cap = cv.VideoCapture(args.image)\n","\n","# take first frame of the video\n","ret,frame = cap.read()\n","frame = cv.resize(frame,(540,1080))\n","# setup initial location of window\n","#x, y, w, h = 150, 250, 50, 100 # simply hardcoded the values #juggle\n","x, y, w, h = 300, 200, 100, 50 # simply hardcoded the values #car\n","track_window = (x, y, w, h)\n","\n","# set up the ROI for tracking\n","roi = frame[y:y+h, x:x+w]\n","hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n","mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n","roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n","cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n","\n","# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n","term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n","\n","while(1):\n","    ret, frame = cap.read()\n","    if ret == True:\n","        #frame = cv.resize(frame,(540,1080))\n","        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n","        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n","\n","        # apply meanshift to get the new location\n","        ret, track_window = cv.meanShift(dst, track_window, term_crit)\n","\n","        # Draw it on image\n","        x,y,w,h = track_window\n","        img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n","        cv.imshow('img2',img2)\n","\n","        k = cv.waitKey(30) & 0xff\n","        if k == 27:\n","            break\n","    else:\n","        break\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","id":"772f6fcb","metadata":{"id":"772f6fcb"},"source":["# CAMShift Algorithm #\n","*taken from: https://github.com/opencv/opencv/blob/3.4/samples/python/tutorial_code/video/meanshift/camshift.py"]},{"cell_type":"code","execution_count":null,"id":"881c7a76","metadata":{"id":"881c7a76"},"outputs":[],"source":["import numpy as np\n","import cv2 as cv\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('image', type=str, help='path to image file')\n","args = parser.parse_args(['.\\Res\\car.mp4']) #File path here\n","\n","cap = cv.VideoCapture(args.image)\n","\n","# take first frame of the video\n","ret,frame = cap.read()\n","\n","# setup initial location of window\n","x, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\n","track_window = (x, y, w, h)\n","\n","# set up the ROI for tracking\n","roi = frame[y:y+h, x:x+w]\n","hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n","mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n","roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n","cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n","\n","# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n","term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n","\n","while(1):\n","    ret, frame = cap.read()\n","\n","    if ret == True:\n","        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n","        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n","\n","        # apply camshift to get the new location\n","        ret, track_window = cv.CamShift(dst, track_window, term_crit)\n","\n","        # Draw it on image\n","        pts = cv.boxPoints(ret)\n","        pts = np.int0(pts)\n","        img2 = cv.polylines(frame,[pts],True, 255,2)\n","        cv.imshow('img2',img2)\n","\n","        k = cv.waitKey(30) & 0xff\n","        if k == 27:\n","            break\n","    else:\n","        break\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","id":"60ee5240","metadata":{"id":"60ee5240"},"source":["# Lucas-Kanade Optical Flow #\n","*taken from: https://github.com/opencv/opencv/blob/3.4/samples/python/tutorial_code/video/optical_flow/optical_flow.py"]},{"cell_type":"code","execution_count":null,"id":"21e08f32","metadata":{"id":"21e08f32","outputId":"b79a3921-3596-404a-c08f-db2770b07906"},"outputs":[{"ename":"error","evalue":"OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[1;32m<ipython-input-49-277f9744489f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# calculate optical flow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Select good points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n"]}],"source":["import numpy as np\n","import cv2 as cv\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('image', type=str, help='path to image file')\n","args = parser.parse_args(['.\\Res\\juggle.mp4']) #File path here\n","\n","cap = cv.VideoCapture(args.image)\n","\n","# params for ShiTomasi corner detection\n","feature_params = dict( maxCorners = 30,\n","                       qualityLevel = 0.1,\n","                       minDistance = 7,\n","                       blockSize = 7 )\n","\n","# Parameters for lucas kanade optical flow\n","lk_params = dict( winSize  = (15, 15),\n","                  maxLevel = 2,\n","                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","# Create some random colors\n","color = np.random.randint(0, 255, (100, 3))\n","\n","# Take first frame and find corners in it\n","ret, old_frame = cap.read()\n","old_frame = cv.resize(old_frame,(540,1080))\n","#old_frame = cv.resize(old_frame,(540,540))\n","old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n","p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n","\n","# Create a mask image for drawing purposes\n","mask = np.zeros_like(old_frame)\n","\n","while(1):\n","    ret, frame = cap.read()\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","    \n","    frame = cv.resize(frame,(540,1080))\n","    #frame = cv.resize(old_frame,(540,540))\n","    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n","\n","    # calculate optical flow\n","    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n","\n","    # Select good points\n","    if p1 is not None:\n","        good_new = p1[st==1]\n","        good_old = p0[st==1]\n","\n","    # draw the tracks\n","    for i, (new, old) in enumerate(zip(good_new, good_old)):\n","        a, b = new.ravel()\n","        c, d = old.ravel()\n","        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n","        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n","    img = cv.add(frame, mask)\n","\n","    cv.imshow('frame', img)\n","    k = cv.waitKey(30) & 0xff\n","    if k == 27:\n","        break\n","\n","    # Now update the previous frame and previous points\n","    old_gray = frame_gray.copy()\n","    p0 = good_new.reshape(-1, 1, 2)\n","\n","cv.destroyAllWindows()"]},{"cell_type":"markdown","id":"5d8d7b44","metadata":{"id":"5d8d7b44"},"source":["# Dense Optical Flow (Farneback Algorithm) #\n","*taken from: https://github.com/opencv/opencv/blob/3.4/samples/python/tutorial_code/video/optical_flow/optical_flow_dense.py"]},{"cell_type":"code","execution_count":null,"id":"30639438","metadata":{"id":"30639438","outputId":"cc89af25-d4c9-4f6a-aff0-da5df2051e63"},"outputs":[{"name":"stdout","output_type":"stream","text":["No frames grabbed!\n"]}],"source":["import numpy as np\n","import cv2 as cv\n","parser = argparse.ArgumentParser()\n","parser.add_argument('image')\n","args = parser.parse_args(['.\\Res\\marble.mp4']) #File path here\n","cap = cv.VideoCapture(args.image)\n","\n","ret, frame1 = cap.read()\n","frame1 = cv.resize(frame1,(540,540))\n","#frame1 = cv.resize(frame1,(1080,1080))\n","prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n","hsv = np.zeros_like(frame1)\n","#cv.imshow('hsv',hsv)\n","hsv[..., 1] = 255\n","#cv.imshow('hsv2',hsv)\n","while(1):\n","    ret, frame2 = cap.read()\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","    frame2 = cv.resize(frame2,(540,540))\n","    #frame2 = cv.resize(frame1,(1080,1080))\n","    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n","    #(prev,next,_,pyr_scale,layers,winsize,iter,poly_n,poly_sigma,flags)\n","    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n","    hsv[..., 0] = ang*180/np.pi/2\n","    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n","    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n","    cv.imshow('frame2', bgr)\n","    k = cv.waitKey(30) & 0xff\n","    if k == 27:\n","        break\n","    elif k == ord('s'):\n","        cv.imwrite('opticalfb.png', frame2)\n","        cv.imwrite('opticalhsv.png', bgr)\n","    prvs = next\n","\n","cv.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"ac5c0602","metadata":{"id":"ac5c0602"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}